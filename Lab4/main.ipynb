{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73009ca",
   "metadata": {},
   "source": [
    "# Lab Assignment 4: Exploration of Different Diff Algorithms on Open-Source Repositories\n",
    "\n",
    "**Course:** CS202 Software Tools and Techniques for CSE  \n",
    "**Date:** 25th August 2025\n",
    "\n",
    "## Objective\n",
    "The purpose of this lab is to explore differences in diff outputs for Open-Source Repositories in the wild. We analyze the impact of different diff algorithms (Myers vs Histogram) on code and non-code artifacts.\n",
    "\n",
    "## Repository Selection\n",
    "We selected three medium-to-large scale open-source repositories:\n",
    "1. **Retrofit** - A type-safe HTTP client for Android and Java\n",
    "2. **Glide** - An image loading and caching library for Android\n",
    "3. **Timber** - A logger with a small, extensible API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6832f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import re\n",
    "from pydriller import Repository\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88834c",
   "metadata": {},
   "source": [
    "## Repository Setup\n",
    "\n",
    "First, let's clone the selected repositories for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the selected repositories\n",
    "repositories = {\n",
    "    'retrofit': 'https://github.com/square/retrofit.git',\n",
    "    'glide': 'https://github.com/bumptech/glide.git',\n",
    "    'timber': 'https://github.com/JakeWharton/timber.git'\n",
    "}\n",
    "\n",
    "# Clone repositories (uncomment if not already cloned)\n",
    "# for name, url in repositories.items():\n",
    "#     !git clone {url} {name}\n",
    "#     print(f\"Cloned {name} repository\")\n",
    "\n",
    "print(\"Repository setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fbd14",
   "metadata": {},
   "source": [
    "## Diff Algorithm Implementation\n",
    "\n",
    "We implement functions to extract diffs using both Myers (default) and Histogram algorithms, then compare their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_myers_diff(repo_path, commit_hash, parent_hash, file_path):\n",
    "    \"\"\"Get diff using Myers algorithm (git default).\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"diff\", parent_hash, commit_hash, \"--\", file_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=True,\n",
    "            errors=\"replace\"\n",
    "        )\n",
    "        \n",
    "        # Extract only the actual diff content (skip headers)\n",
    "        lines = result.stdout.splitlines()\n",
    "        diff_content = []\n",
    "        \n",
    "        include_line = False\n",
    "        for line in lines:\n",
    "            if line.startswith(\"@@\"):\n",
    "                include_line = True\n",
    "            if include_line:\n",
    "                diff_content.append(line)\n",
    "        \n",
    "        return \"\\n\".join(diff_content).strip()\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error: {e.stderr.strip()}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def get_histogram_diff(repo_path, commit_hash, parent_hash, file_path):\n",
    "    \"\"\"Get diff using Histogram algorithm.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"diff\", \"--histogram\", parent_hash, commit_hash, \"--\", file_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=True,\n",
    "            errors=\"replace\"\n",
    "        )\n",
    "        \n",
    "        # Extract only the actual diff content (skip headers)\n",
    "        lines = result.stdout.splitlines()\n",
    "        diff_content = []\n",
    "        \n",
    "        include_line = False\n",
    "        for line in lines:\n",
    "            if line.startswith(\"@@\"):\n",
    "                include_line = True\n",
    "            if include_line:\n",
    "                diff_content.append(line)\n",
    "        \n",
    "        return \"\\n\".join(diff_content).strip()\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error: {e.stderr.strip()}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30375e4d",
   "metadata": {},
   "source": [
    "## File Classification\n",
    "\n",
    "We classify files into different categories to analyze the impact of diff algorithms on different types of artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_file_type(file_path):\n",
    "    \"\"\"Classify files into different categories based on path and extension.\"\"\"\n",
    "    if not file_path:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    path_lower = file_path.lower()\n",
    "    \n",
    "    # Test files\n",
    "    if any(test_indicator in path_lower for test_indicator in ['test', 'spec', '/tests/', '/test/']):\n",
    "        return \"test\"\n",
    "    \n",
    "    # Source code files\n",
    "    code_extensions = ['.java', '.kt', '.py', '.js', '.ts', '.cpp', '.c', '.h', '.cs']\n",
    "    if any(path_lower.endswith(ext) for ext in code_extensions):\n",
    "        return \"source_code\"\n",
    "    \n",
    "    # Build and configuration files\n",
    "    build_files = ['build.gradle', 'pom.xml', 'package.json', 'makefile', 'cmake']\n",
    "    config_extensions = ['.gradle', '.xml', '.json', '.yaml', '.yml', '.properties', '.config']\n",
    "    if any(build_file in path_lower for build_file in build_files) or \\\n",
    "       any(path_lower.endswith(ext) for ext in config_extensions):\n",
    "        return \"build_config\"\n",
    "    \n",
    "    # Documentation files\n",
    "    doc_files = ['readme', 'changelog', 'license', 'contributing']\n",
    "    doc_extensions = ['.md', '.txt', '.rst', '.adoc']\n",
    "    if any(doc_file in path_lower for doc_file in doc_files) or \\\n",
    "       any(path_lower.endswith(ext) for ext in doc_extensions):\n",
    "        return \"documentation\"\n",
    "    \n",
    "    # Resource files\n",
    "    resource_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico', '.css', '.html']\n",
    "    if any(path_lower.endswith(ext) for ext in resource_extensions):\n",
    "        return \"resources\"\n",
    "    \n",
    "    return \"other\"\n",
    "\n",
    "# Test the classification function\n",
    "test_files = [\n",
    "    \"src/main/java/com/example/Main.java\",\n",
    "    \"src/test/java/com/example/MainTest.java\",\n",
    "    \"build.gradle\",\n",
    "    \"README.md\",\n",
    "    \"app/src/main/res/drawable/icon.png\"\n",
    "]\n",
    "\n",
    "print(\"File classification examples:\")\n",
    "for file_path in test_files:\n",
    "    print(f\"{file_path} -> {classify_file_type(file_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34baf74",
   "metadata": {},
   "source": [
    "## Repository Analysis Function\n",
    "\n",
    "Main function to analyze a repository and compare diff algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_repository_diffs(repo_path, repo_name, commit_limit=200):\n",
    "    \"\"\"Analyze diff discrepancies in a repository.\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Analyzing {repo_name} repository ===\")\n",
    "    \n",
    "    results = []\n",
    "    commits_processed = 0\n",
    "    total_files = 0\n",
    "    \n",
    "    try:\n",
    "        for commit in Repository(repo_path, histogram_diff=False).traverse_commits():\n",
    "            if commits_processed >= commit_limit:\n",
    "                break\n",
    "            \n",
    "            # Skip commits without parents (initial commit)\n",
    "            if not commit.parents:\n",
    "                continue\n",
    "            \n",
    "            parent_sha = commit.parents[0]\n",
    "            \n",
    "            for modified_file in commit.modified_files:\n",
    "                file_path = modified_file.new_path or modified_file.old_path\n",
    "                \n",
    "                if not file_path:\n",
    "                    continue\n",
    "                \n",
    "                # Get diffs using both algorithms\n",
    "                histogram_diff = get_histogram_diff(repo_path, commit.hash, parent_sha, file_path)\n",
    "                myers_diff = get_myers_diff(repo_path, commit.hash, parent_sha, file_path)\n",
    "                \n",
    "                # Skip empty diffs\n",
    "                if not histogram_diff.strip() or not myers_diff.strip():\n",
    "                    continue\n",
    "                \n",
    "                # Check for discrepancy\n",
    "                has_discrepancy = histogram_diff != myers_diff\n",
    "                file_category = classify_file_type(file_path)\n",
    "                \n",
    "                results.append({\n",
    "                    \"repository\": repo_name,\n",
    "                    \"commit_hash\": commit.hash,\n",
    "                    \"parent_hash\": parent_sha,\n",
    "                    \"file_path\": file_path,\n",
    "                    \"file_category\": file_category,\n",
    "                    \"commit_message\": commit.msg,\n",
    "                    \"histogram_diff\": histogram_diff,\n",
    "                    \"myers_diff\": myers_diff,\n",
    "                    \"has_discrepancy\": has_discrepancy,\n",
    "                    \"histogram_diff_size\": len(histogram_diff),\n",
    "                    \"myers_diff_size\": len(myers_diff)\n",
    "                })\n",
    "                \n",
    "                total_files += 1\n",
    "            \n",
    "            commits_processed += 1\n",
    "            \n",
    "            if commits_processed % 50 == 0:\n",
    "                print(f\"Processed {commits_processed} commits, {total_files} files\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing repository {repo_name}: {e}\")\n",
    "    \n",
    "    print(f\"Analysis complete: {commits_processed} commits, {total_files} files\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fb1da",
   "metadata": {},
   "source": [
    "## Running Analysis on Selected Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all three repositories\n",
    "all_results = []\n",
    "repository_paths = ['retrofit', 'glide', 'timber']\n",
    "\n",
    "for repo_name in repository_paths:\n",
    "    try:\n",
    "        repo_results = analyze_repository_diffs(repo_name, repo_name, commit_limit=100)\n",
    "        all_results.extend(repo_results)\n",
    "        \n",
    "        # Save individual repository results\n",
    "        if repo_results:\n",
    "            repo_df = pd.DataFrame(repo_results)\n",
    "            repo_df.to_csv(f\"{repo_name}_diff_analysis.csv\", index=False)\n",
    "            print(f\"Saved {len(repo_results)} results for {repo_name}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to analyze {repo_name}: {e}\")\n",
    "\n",
    "# Create master dataframe\n",
    "if all_results:\n",
    "    master_df = pd.DataFrame(all_results)\n",
    "    master_df.to_csv(\"diff_algorithms_comparison.csv\", index=False)\n",
    "    print(f\"\\nMaster dataset created with {len(all_results)} total entries\")\n",
    "else:\n",
    "    print(\"No results collected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1b75f",
   "metadata": {},
   "source": [
    "## Analysis and Visualization\n",
    "\n",
    "Analyzing the discrepancies between diff algorithms and visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7164567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results for analysis\n",
    "if 'master_df' in locals() and not master_df.empty:\n",
    "    df = master_df\n",
    "else:\n",
    "    # Try to load from CSV if available\n",
    "    try:\n",
    "        df = pd.read_csv(\"diff_algorithms_comparison.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No data available for analysis\")\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"=== Diff Algorithm Comparison Analysis ===\")\n",
    "    print(f\"Total files analyzed: {len(df):,}\")\n",
    "    print(f\"Files with discrepancies: {df['has_discrepancy'].sum():,}\")\n",
    "    print(f\"Discrepancy rate: {(df['has_discrepancy'].sum() / len(df)) * 100:.2f}%\")\n",
    "    \n",
    "    # Repository-wise analysis\n",
    "    print(\"\\n=== Repository-wise Analysis ===\")\n",
    "    repo_analysis = df.groupby('repository').agg({\n",
    "        'has_discrepancy': ['count', 'sum'],\n",
    "        'file_category': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    repo_analysis.columns = ['total_files', 'discrepancies', 'files_analyzed']\n",
    "    repo_analysis['discrepancy_rate'] = (repo_analysis['discrepancies'] / repo_analysis['total_files'] * 100).round(2)\n",
    "    print(repo_analysis)\n",
    "    \n",
    "    # File category analysis\n",
    "    print(\"\\n=== File Category Analysis ===\")\n",
    "    category_analysis = df.groupby('file_category').agg({\n",
    "        'has_discrepancy': ['count', 'sum']\n",
    "    })\n",
    "    \n",
    "    category_analysis.columns = ['total_files', 'discrepancies']\n",
    "    category_analysis['discrepancy_rate'] = (category_analysis['discrepancies'] / category_analysis['total_files'] * 100).round(2)\n",
    "    category_analysis = category_analysis.sort_values('discrepancy_rate', ascending=False)\n",
    "    print(category_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcee2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Diff Algorithm Comparison Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Overall discrepancy distribution\n",
    "    discrepancy_counts = df['has_discrepancy'].value_counts()\n",
    "    axes[0, 0].pie(discrepancy_counts.values, \n",
    "                   labels=['No Discrepancy', 'Has Discrepancy'], \n",
    "                   autopct='%1.1f%%',\n",
    "                   colors=['lightgreen', 'lightcoral'])\n",
    "    axes[0, 0].set_title('Overall Discrepancy Distribution')\n",
    "    \n",
    "    # 2. Discrepancies by repository\n",
    "    repo_discrepancies = df[df['has_discrepancy'] == True]['repository'].value_counts()\n",
    "    if not repo_discrepancies.empty:\n",
    "        axes[0, 1].bar(repo_discrepancies.index, repo_discrepancies.values, color='skyblue')\n",
    "        axes[0, 1].set_title('Discrepancies by Repository')\n",
    "        axes[0, 1].set_xlabel('Repository')\n",
    "        axes[0, 1].set_ylabel('Number of Discrepancies')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Discrepancies by file category\n",
    "    category_discrepancies = df[df['has_discrepancy'] == True]['file_category'].value_counts()\n",
    "    if not category_discrepancies.empty:\n",
    "        axes[1, 0].bar(category_discrepancies.index, category_discrepancies.values, color='lightcoral')\n",
    "        axes[1, 0].set_title('Discrepancies by File Category')\n",
    "        axes[1, 0].set_xlabel('File Category')\n",
    "        axes[1, 0].set_ylabel('Number of Discrepancies')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Diff size comparison\n",
    "    if df['histogram_diff_size'].sum() > 0 and df['myers_diff_size'].sum() > 0:\n",
    "        axes[1, 1].scatter(df['myers_diff_size'], df['histogram_diff_size'], alpha=0.6)\n",
    "        axes[1, 1].plot([0, df['myers_diff_size'].max()], [0, df['myers_diff_size'].max()], 'r--', alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('Myers Diff Size (characters)')\n",
    "        axes[1, 1].set_ylabel('Histogram Diff Size (characters)')\n",
    "        axes[1, 1].set_title('Diff Size Comparison')\n",
    "        axes[1, 1].set_xlim(0, None)\n",
    "        axes[1, 1].set_ylim(0, None)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('diff_algorithm_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nVisualization saved as 'diff_algorithm_analysis.png'\")\n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd7e96",
   "metadata": {},
   "source": [
    "## Detailed Discrepancy Analysis\n",
    "\n",
    "Looking at specific examples of discrepancies between algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Find examples of discrepancies\n",
    "    discrepancy_examples = df[df['has_discrepancy'] == True].head(5)\n",
    "    \n",
    "    if not discrepancy_examples.empty:\n",
    "        print(\"=== Sample Discrepancy Examples ===\")\n",
    "        \n",
    "        for idx, row in discrepancy_examples.iterrows():\n",
    "            print(f\"\\n--- Example {idx + 1} ---\")\n",
    "            print(f\"Repository: {row['repository']}\")\n",
    "            print(f\"File: {row['file_path']}\")\n",
    "            print(f\"Category: {row['file_category']}\")\n",
    "            print(f\"Commit: {row['commit_hash'][:8]}\")\n",
    "            print(f\"Myers diff size: {row['myers_diff_size']} chars\")\n",
    "            print(f\"Histogram diff size: {row['histogram_diff_size']} chars\")\n",
    "            \n",
    "            # Show first few lines of each diff if they're not too long\n",
    "            if len(row['myers_diff']) < 500:\n",
    "                print(f\"\\nMyers diff excerpt:\\n{row['myers_diff'][:200]}...\")\n",
    "            if len(row['histogram_diff']) < 500:\n",
    "                print(f\"\\nHistogram diff excerpt:\\n{row['histogram_diff'][:200]}...\")\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(\"\\n=== Statistical Analysis ===\")\n",
    "    \n",
    "    discrepancy_df = df[df['has_discrepancy'] == True]\n",
    "    \n",
    "    if not discrepancy_df.empty:\n",
    "        size_diff = discrepancy_df['histogram_diff_size'] - discrepancy_df['myers_diff_size']\n",
    "        \n",
    "        print(f\"Average size difference: {size_diff.mean():.2f} characters\")\n",
    "        print(f\"Median size difference: {size_diff.median():.2f} characters\")\n",
    "        print(f\"Standard deviation: {size_diff.std():.2f} characters\")\n",
    "        \n",
    "        print(f\"\\nFiles where Histogram > Myers: {(size_diff > 0).sum()}\")\n",
    "        print(f\"Files where Myers > Histogram: {(size_diff < 0).sum()}\")\n",
    "        print(f\"Files with same size: {(size_diff == 0).sum()}\")\n",
    "    \n",
    "    # Save detailed analysis\n",
    "    analysis_summary = {\n",
    "        'total_files': len(df),\n",
    "        'total_discrepancies': df['has_discrepancy'].sum(),\n",
    "        'discrepancy_rate': (df['has_discrepancy'].sum() / len(df)) * 100,\n",
    "        'repositories_analyzed': df['repository'].nunique(),\n",
    "        'file_categories': df['file_category'].nunique()\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame([analysis_summary])\n",
    "    summary_df.to_csv(\"diff_analysis_summary.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nAnalysis summary saved to 'diff_analysis_summary.csv'\")\n",
    "    print(f\"Detailed results saved to 'diff_algorithms_comparison.csv'\")\n",
    "else:\n",
    "    print(\"No data available for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db720b1",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "This notebook provides a comprehensive comparison of diff algorithms (Myers vs Histogram) across multiple open-source repositories.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Algorithm Differences**: \n",
    "   - Myers algorithm (default git diff)\n",
    "   - Histogram algorithm (alternative approach)\n",
    "   - Discrepancies found in diff outputs\n",
    "\n",
    "2. **File Type Impact**:\n",
    "   - Source code files vs configuration files\n",
    "   - Documentation vs resource files\n",
    "   - Different categories show varying discrepancy rates\n",
    "\n",
    "3. **Repository Analysis**:\n",
    "   - Multi-repository comparison\n",
    "   - Statistical analysis of differences\n",
    "   - Visualization of patterns\n",
    "\n",
    "### Key Datasets Generated:\n",
    "- `retrofit_diff_analysis.csv`: Retrofit repository analysis\n",
    "- `glide_diff_analysis.csv`: Glide repository analysis  \n",
    "- `timber_diff_analysis.csv`: Timber repository analysis\n",
    "- `diff_algorithms_comparison.csv`: Combined analysis results\n",
    "- `diff_analysis_summary.csv`: Statistical summary\n",
    "\n",
    "### Applications:\n",
    "- Understanding diff algorithm behavior\n",
    "- Tool selection for code analysis\n",
    "- Quality assessment of diff outputs\n",
    "- Research in software evolution\n",
    "- Development of better diff algorithms\n",
    "\n",
    "### Visualization Output:\n",
    "- `diff_algorithm_analysis.png`: Comprehensive analysis charts\n",
    "\n",
    "This analysis helps understand when and why different diff algorithms produce varying outputs, which is crucial for tools that depend on diff analysis for software engineering tasks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
