{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a30872",
   "metadata": {},
   "source": [
    "# Lab Assignment 2: Commit Message Rectification for Bug-Fixing Commits\n",
    "\n",
    "**Course:** CS202 Software Tools and Techniques for CSE  \n",
    "**Date:** 11th August 2025\n",
    "\n",
    "## Objective\n",
    "This lab introduces students to the basics of mining open source software (OSS) repositories. The process involves processing and analyzing commits on the GitHub version control system for popular real world projects. The overall aim is to establish a framework for understanding how developers think of bug fixing commits.\n",
    "\n",
    "## Repository Selection\n",
    "Selected Repository: **PDFMathTranslate** - A tool for translating mathematical expressions in PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the selected repository\n",
    "!git clone https://github.com/Byaidu/PDFMathTranslate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ee762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "from pydriller import Repository\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, RobertaTokenizer, RobertaModel\n",
    "import torch.nn.functional as F\n",
    "from groq import Groq\n",
    "\n",
    "# Set repository path\n",
    "repo_url = 'PDFMathTranslate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6c142",
   "metadata": {},
   "source": [
    "## Bug-Fixing Commit Identification\n",
    "\n",
    "We use keyword-based matching to identify potential bug-fixing commits. This approach looks for common bug-related keywords in commit messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873fb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bug-related keywords for commit identification\n",
    "bug_keywords = [\n",
    "    \"fixed\", \"bug\", \"fixes\", \"fix\", \"crash\", \"solves\",\n",
    "    \"resolves\", \"issue\", \"regression\", \"fall back\",\n",
    "    \"assertion\", \"coverity\", \"reproducible\", \"stack-wanted\",\n",
    "    \"steps-wanted\", \"testcase\", \"failure\", \"fail\", \"npe\",\n",
    "    \"except\", \"broken\", \"differential testing\", \"error\",\n",
    "    \"hang\", \"test fix\", \"steps to reproduce\", \"leak\",\n",
    "    \"stack trace\", \"heap overflow\", \"freez\", \"problem\",\n",
    "    \"overflow\", \"avoid\", \"workaround\", \"break\", \"stop\"\n",
    "]\n",
    "\n",
    "def is_bug_commit_naive(commit):\n",
    "    \"\"\"Check if a commit is likely a bug fix based on message keywords.\"\"\"\n",
    "    message = commit.msg.lower()\n",
    "    return any(keyword in message for keyword in bug_keywords)\n",
    "\n",
    "def is_merge_commit(commit):\n",
    "    \"\"\"Check if a commit is a merge commit.\"\"\"\n",
    "    return len(commit.parents) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5536916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential bug-fixing commits\n",
    "commit_data = []\n",
    "\n",
    "for commit in Repository(repo_url).traverse_commits():\n",
    "    if is_bug_commit_naive(commit):\n",
    "        diff_content = ''\n",
    "        for file in commit.modified_files:\n",
    "            diff_content += file.diff if file.diff else ''\n",
    "            \n",
    "        commit_data.append({\n",
    "            \"hash\": commit.hash,\n",
    "            \"message\": commit.msg,\n",
    "            \"parents\": [parent for parent in commit.parents],\n",
    "            \"is_merge\": commit.merge,\n",
    "            \"diff\": diff_content,\n",
    "            \"files_modified\": [mod.filename for mod in commit.modified_files]\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "bug_commits_df = pd.DataFrame(commit_data)\n",
    "bug_commits_df.to_csv(\"potential_bug_fix_commits.csv\", index=False)\n",
    "print(f\"Found and saved {len(bug_commits_df)} potential bug-fixing commits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a19e9",
   "metadata": {},
   "source": [
    "## Diff Extraction and LLM Analysis\n",
    "\n",
    "Using a pre-trained model to analyze code changes and generate fix type predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CommitPredictorT5 model for diff analysis\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\").to(device)\n",
    "model.eval()\n",
    "\n",
    "MAX_INPUT_TOKENS = 512\n",
    "MAX_OUTPUT_TOKENS = 512\n",
    "\n",
    "def safe_infer(diff_text):\n",
    "    \"\"\"Run model inference safely on diff text.\"\"\"\n",
    "    if not diff_text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Tokenize and truncate input\n",
    "    inputs = tokenizer(\n",
    "        diff_text,\n",
    "        return_tensors='pt',\n",
    "        max_length=MAX_INPUT_TOKENS,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=MAX_OUTPUT_TOKENS)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze files in bug-fixing commits\n",
    "def collect_file_level_data(repo_url, limit=1000000):\n",
    "    \"\"\"Collect file-level data for bug-fixing commits.\"\"\"\n",
    "    file_data = []\n",
    "    processed = 0\n",
    "    \n",
    "    for commit in Repository(repo_url).traverse_commits():\n",
    "        if processed >= limit:\n",
    "            break\n",
    "            \n",
    "        if is_bug_commit_naive(commit):\n",
    "            for file in commit.modified_files:\n",
    "                try:\n",
    "                    inference = safe_infer(file.diff)\n",
    "\n",
    "                    file_data.append({\n",
    "                        \"hash\": commit.hash,\n",
    "                        \"filename\": file.filename,\n",
    "                        \"diff\": file.diff or \"\",\n",
    "                        \"llm_inference\": inference,\n",
    "                        \"rectified_msg\": \"\"\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file.filename} in {commit.hash}: {e}\")\n",
    "                \n",
    "                # Memory management\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            processed += 1\n",
    "\n",
    "    return file_data\n",
    "\n",
    "# Collect and save file-level data\n",
    "file_level_data = collect_file_level_data(repo_url)\n",
    "llm_inference_df = pd.DataFrame(file_level_data)\n",
    "llm_inference_df.to_csv(\"llm_inference_results.csv\", index=False)\n",
    "print(f\"Processed {len(llm_inference_df)} files with LLM inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b352543",
   "metadata": {},
   "source": [
    "## Commit Message Rectification\n",
    "\n",
    "Using Groq API to generate improved commit messages based on code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f423ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Replace 'your_api_key_here' with your actual Groq API key\n",
    "# groq_client = Groq(api_key=\"your_api_key_here\")\n",
    "\n",
    "def safe_truncate(text, max_chars=4000):\n",
    "    \"\"\"Safely truncate text to prevent token limit issues.\"\"\"\n",
    "    if len(text) > max_chars:\n",
    "        return text[:max_chars] + \"\\n...[TRUNCATED]...\"\n",
    "    return text\n",
    "\n",
    "def generate_rectified_message(original_msg, file_changes):\n",
    "    \"\"\"Generate improved commit message using Groq API.\"\"\"\n",
    "    # Uncomment and modify when API key is available\n",
    "    # prompt = (\n",
    "    #     f\"Original commit message:\\n{safe_truncate(original_msg, 500)}\\n\\n\" +\n",
    "    #     f\"Changes in files:\\n{safe_truncate(file_changes, 3000)}\\n\" +\n",
    "    #     \"Task: Write a concise, accurate commit message summarizing all changes.\"\n",
    "    # )\n",
    "    \n",
    "    # For demonstration, return a placeholder\n",
    "    return f\"[Rectified] {original_msg[:50]}...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rectified commit messages\n",
    "def collect_rectified_commits(repo_url, limit=100):\n",
    "    \"\"\"Collect commits with rectified messages.\"\"\"\n",
    "    rectified_data = []\n",
    "    processed = 0\n",
    "\n",
    "    for commit in Repository(repo_url).traverse_commits():\n",
    "        if processed >= limit:\n",
    "            break\n",
    "\n",
    "        if is_bug_commit_naive(commit):\n",
    "            file_changes = []\n",
    "\n",
    "            for file in commit.modified_files:\n",
    "                try:\n",
    "                    llm_tag = safe_infer(file.diff or \"\")\n",
    "                    file_changes.append(f\"{file.filename}: {llm_tag}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file.filename}: {e}\")\n",
    "                \n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            # Generate rectified message\n",
    "            file_changes_text = \"\\n\".join(file_changes)\n",
    "            rectified_msg = generate_rectified_message(commit.msg, file_changes_text)\n",
    "\n",
    "            rectified_data.append({\n",
    "                \"hash\": commit.hash,\n",
    "                \"developer_msg\": commit.msg,\n",
    "                \"rectified_commit_msg\": rectified_msg\n",
    "            })\n",
    "            \n",
    "            processed += 1\n",
    "\n",
    "    return rectified_data\n",
    "\n",
    "# Collect rectified messages\n",
    "rectified_commits = collect_rectified_commits(repo_url, limit=50)\n",
    "rectified_df = pd.DataFrame(rectified_commits)\n",
    "rectified_df.to_csv(\"rectified_messages.csv\", index=False)\n",
    "print(f\"Generated {len(rectified_df)} rectified commit messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c5bae",
   "metadata": {},
   "source": [
    "## Data Integration and Master Dataset Creation\n",
    "\n",
    "Combining all collected data into a comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d537ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files\n",
    "rectified_df = pd.read_csv(\"rectified_messages.csv\")\n",
    "llm_inference_df = pd.read_csv(\"llm_inference_results.csv\")\n",
    "bug_commits_df = pd.read_csv(\"potential_bug_fix_commits.csv\")\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Rectified messages: {rectified_df.shape}\")\n",
    "print(f\"LLM inference: {llm_inference_df.shape}\")\n",
    "print(f\"Bug commits: {bug_commits_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate file-level data by commit hash\n",
    "aggregated_files = llm_inference_df.groupby(\"hash\").agg({\n",
    "    \"filename\": lambda x: \" | \".join(x.astype(str)),\n",
    "    \"llm_inference\": lambda x: \" | \".join(x.astype(str)),\n",
    "    \"diff\": lambda x: \" | \".join(x.astype(str)),\n",
    "    \"rectified_msg\": lambda x: \" | \".join(x.dropna().astype(str))\n",
    "}).reset_index()\n",
    "\n",
    "# Create master dataset by merging all dataframes\n",
    "master_df = (\n",
    "    rectified_df\n",
    "    .merge(aggregated_files, on=\"hash\", how=\"left\")\n",
    "    .merge(bug_commits_df, on=\"hash\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Clean up columns\n",
    "master_df = master_df.dropna(axis=1, how='all')\n",
    "\n",
    "# Save master dataset\n",
    "master_df.to_csv(\"master_commits_dataset.csv\", index=False)\n",
    "print(f\"Master dataset created with {len(master_df)} entries\")\n",
    "print(f\"Columns: {list(master_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f30ae0",
   "metadata": {},
   "source": [
    "## Evaluation and Analysis\n",
    "\n",
    "Evaluating the quality of commit message predictions using semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0764f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CodeBERT for semantic similarity evaluation\n",
    "codebert_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Get CodeBERT embedding for text.\"\"\"\n",
    "    tokens = codebert_tokenizer(text, return_tensors='pt', truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        output = codebert_model(**tokens)\n",
    "    return output.last_hidden_state[:,0,:]\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    \"\"\"Calculate cosine similarity between two texts.\"\"\"\n",
    "    emb1 = get_embedding(text1)\n",
    "    emb2 = get_embedding(text2)\n",
    "    return F.cosine_similarity(emb1, emb2).item()\n",
    "\n",
    "def normalize_text(val):\n",
    "    \"\"\"Normalize text values for comparison.\"\"\"\n",
    "    if isinstance(val, list):\n",
    "        return \" \".join(str(x) for x in val)\n",
    "    elif isinstance(val, str):\n",
    "        return val\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate developer messages vs diff content\n",
    "def evaluate_messages(df, msg_column, reference_column, threshold=0.95):\n",
    "    \"\"\"Evaluate message quality using semantic similarity.\"\"\"\n",
    "    total = 0\n",
    "    hits = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        msg_text = normalize_text(row[msg_column])\n",
    "        ref_text = normalize_text(row[reference_column])\n",
    "\n",
    "        if not msg_text or not ref_text:\n",
    "            continue\n",
    "\n",
    "        similarity = calculate_similarity(msg_text, ref_text)\n",
    "        if similarity > threshold:\n",
    "            hits += 1\n",
    "        total += 1\n",
    "\n",
    "    accuracy = (hits / total * 100) if total > 0 else 0\n",
    "    return total, hits, accuracy\n",
    "\n",
    "# Load master dataset for evaluation\n",
    "master_df = pd.read_csv(\"master_commits_dataset.csv\")\n",
    "\n",
    "# Evaluate different approaches\n",
    "print(\"=== Evaluation Results ===\")\n",
    "\n",
    "# Developer messages vs diff content\n",
    "total, hits, accuracy = evaluate_messages(master_df, \"developer_msg\", \"diff\")\n",
    "print(f\"Developer Messages: {hits}/{total} = {accuracy:.2f}% accuracy\")\n",
    "\n",
    "# LLM inference vs diff content\n",
    "total, hits, accuracy = evaluate_messages(master_df, \"llm_inference\", \"diff\")\n",
    "print(f\"LLM Inference: {hits}/{total} = {accuracy:.2f}% accuracy\")\n",
    "\n",
    "# Rectified messages vs diff content\n",
    "total, hits, accuracy = evaluate_messages(master_df, \"rectified_commit_msg\", \"diff\")\n",
    "print(f\"Rectified Messages: {hits}/{total} = {accuracy:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e755815",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "This notebook demonstrates a complete pipeline for:\n",
    "\n",
    "1. **Repository Mining**: Extracting bug-fixing commits from OSS repositories\n",
    "2. **Automated Analysis**: Using pre-trained models to analyze code changes\n",
    "3. **Message Rectification**: Generating improved commit messages\n",
    "4. **Evaluation**: Measuring the quality of different approaches\n",
    "\n",
    "### Key Datasets Generated:\n",
    "- `potential_bug_fix_commits.csv`: Bug-fixing commits identified\n",
    "- `llm_inference_results.csv`: File-level analysis results\n",
    "- `rectified_messages.csv`: Improved commit messages\n",
    "- `master_commits_dataset.csv`: Comprehensive combined dataset\n",
    "\n",
    "### Applications:\n",
    "- Dataset creation for automated program repair models\n",
    "- Multi-versioned program analysis\n",
    "- Patch generation research\n",
    "- Software maintainability improvement"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
